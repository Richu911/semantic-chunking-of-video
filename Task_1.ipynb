{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Richu911/semantic-chunking-of-video/blob/main/Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygS1y_6Fo8eL"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5WK6ec3cwmV"
      },
      "source": [
        "I had to study about everything. I could not do the 2nd task because of my exams.\n",
        "If GPU is not available please use cpu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-xt9N8nmgQa"
      },
      "source": [
        "## Installing whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuorfcebDQVs"
      },
      "source": [
        "Install whisper and pydub using the following commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cx05Vqaynu18",
        "outputId": "66dbacba-2781-4036-91cf-a3c1bc829906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-r14gvizm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-r14gvizm\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=905aa81f1e57e6f4cbfb6d2f3e9ca93b6102a81ac632db82f65581744046630f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t3pub4ax/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1JKVVukZXeb"
      },
      "source": [
        "## Segmentation of audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kec-8lYyZjlO"
      },
      "source": [
        "This is the code to get the audio file so that the audio file is preserved when i restart the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lux6I7ZAzxTW",
        "outputId": "1a199870-e68e-45de-e404-c1162e239b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-11 16:56:24--  https://link.storjshare.io/s/ju5eiyysp4ejysehlbr5nabeeqga/sarvam/sarvam.mp3?download=1\n",
            "Resolving link.storjshare.io (link.storjshare.io)... 136.0.77.2\n",
            "Connecting to link.storjshare.io (link.storjshare.io)|136.0.77.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25200813 (24M) [audio/mpeg]\n",
            "Saving to: ‘sarvam.mp3?download=1’\n",
            "\n",
            "sarvam.mp3?download 100%[===================>]  24.03M  9.46MB/s    in 2.5s    \n",
            "\n",
            "2024-06-11 16:56:28 (9.46 MB/s) - ‘sarvam.mp3?download=1’ saved [25200813/25200813]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://link.storjshare.io/s/ju5eiyysp4ejysehlbr5nabeeqga/sarvam/sarvam.mp3?download=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzUr7N3FMhAY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the original file path and name\n",
        "original_file_path = '/content/sarvam.mp3?download=1'\n",
        "\n",
        "# Set the new file name\n",
        "new_file_name = 'sarvam.mp3'\n",
        "\n",
        "# Use os.rename() to rename the file\n",
        "os.rename(original_file_path, new_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mq0MONe9cEf"
      },
      "source": [
        "I segmented the audio into 15 second chunks using ffmpeg which is a popular audio processing tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T7bP_81UXvbY",
        "outputId": "58d2bb12-4b5a-4df3-cb5f-c4e8b721fd63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;35m[mp3 @ 0x5aa65f777100] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
            "\u001b[0mInput #0, mp3, from '/content/sarvam.mp3':\n",
            "  Metadata:\n",
            "    encoder         : Lavf60.21.101\n",
            "  Duration: 00:26:15.05, start: 0.000000, bitrate: 128 kb/s\n",
            "  Stream #0:0: Audio: mp3, 48000 Hz, stereo, fltp, 128 kb/s\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_000.mp3' for writing\n",
            "Output #0, segment, to 'sarvam_%03d.mp3':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Audio: mp3, 48000 Hz, stereo, fltp, 128 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "size=N/A time=00:00:00.00 bitrate=N/A speed=N/A    \r\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_001.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_002.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_003.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_004.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_005.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_006.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_007.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_008.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_009.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_010.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_011.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_012.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_013.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_014.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_015.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_016.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_017.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_018.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_019.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_020.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_021.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_022.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_023.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_024.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_025.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_026.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_027.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_028.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_029.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_030.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_031.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_032.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_033.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_034.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_035.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_036.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_037.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_038.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_039.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_040.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_041.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_042.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_043.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_044.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_045.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_046.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_047.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_048.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_049.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_050.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_051.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_052.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_053.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_054.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_055.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_056.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_057.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_058.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_059.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_060.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_061.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_062.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_063.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_064.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_065.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_066.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_067.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_068.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_069.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_070.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_071.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_072.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_073.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_074.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_075.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_076.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_077.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_078.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_079.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_080.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_081.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_082.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_083.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_084.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_085.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_086.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_087.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_088.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_089.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_090.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_091.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_092.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_093.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_094.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_095.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_096.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_097.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_098.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_099.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_100.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_101.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_102.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_103.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_104.mp3' for writing\n",
            "\u001b[1;35m[segment @ 0x5aa65f77c140] \u001b[0mOpening 'sarvam_105.mp3' for writing\n",
            "size=N/A time=00:26:15.02 bitrate=N/A speed=1.47e+03x    \n",
            "video:0kB audio:24610kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
          ]
        }
      ],
      "source": [
        "# segmented time is 0.25 min (15 sec)\n",
        "# sarvam_%03d.mp3 is the output file name, where %03d is a placeholder for the segment number (from 001 to 999)\n",
        "!ffmpeg -i /content/sarvam.mp3 \\\n",
        "-c copy -map 0 -segment_time 00:00:15 \\\n",
        "-f segment -reset_timestamps 1 sarvam_%03d.mp3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4L6gD4Tn6Dl"
      },
      "source": [
        "## Importing whisper and transcribing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwaNOqq1cPeU"
      },
      "source": [
        "The reason why i had to iterate each segment was because you mentioned that i had to chunk each audio segment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RlSkOah2oZ0m",
        "outputId": "f1a343cb-34f7-4291-f8c8-f7167eaf1f24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9a64102b5d17>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mi_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{i:03d}\"\u001b[0m  \u001b[0;31m# Format as a 3-digit string with leading zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"sarvam_{i_str}.mp3\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# transcribing audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mn_audio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0maudio_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_audio_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# encoder forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_get_audio_features\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0maudio_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0maudio_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         if audio_features.dtype != (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mkv_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     ):\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mqkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import pydub\n",
        "\n",
        "# loading whisper model\n",
        "model = whisper.load_model(\"base\")\n",
        "result = []\n",
        "\n",
        "for i in range(0, 105):  # Loop up to 105\n",
        "    i_str = f\"{i:03d}\"  # Format as a 3-digit string with leading zeros\n",
        "\n",
        "    text = model.transcribe(f\"sarvam_{i_str}.mp3\") # transcribing audio\n",
        "\n",
        "    result.append(text[\"text\"])\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5SAVAqxm2jg"
      },
      "source": [
        "## Creating a dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhPuLwrqyZM9"
      },
      "source": [
        "Click the table icon to view an imersive table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QzWwnaH4yGbw",
        "outputId": "51c44246-155d-4140-9c7b-1a397fb8481c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 105,\n  \"fields\": [\n    {\n      \"column\": \"start_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.613076688610635,\n        \"min\": 0.0,\n        \"max\": 26.01,\n        \"num_unique_values\": 105,\n        \"samples\": [\n          7.31,\n          16.16,\n          16.01\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.622870746963274,\n        \"min\": 0.15,\n        \"max\": 26.15,\n        \"num_unique_values\": 105,\n        \"samples\": [\n          7.46,\n          16.31,\n          16.16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 105,\n        \"samples\": [\n          \" So the film is definitely something that people can use to things. And that's the essence of what this OpenHap is. So what does it mean to people in the audience here who are either doing their own startups or a business or?\",\n          \" in areas of customer service, et cetera. When you want to do something very specific, today, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call, or you're extremely upset that you're...\",\n          \" But it's interesting. But I think the first thing that we said is, I think that, and I don't think that this is, I think there will come a time when, you know, in...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b6cef982-9ad0-4f67-9ffa-aedb2d125dca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.15</td>\n",
              "      <td>Congratulations to you Mr. Raghavan for that....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.16</td>\n",
              "      <td>0.30</td>\n",
              "      <td>Energy downer or something? Let's hear it. Ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.45</td>\n",
              "      <td>Honestly, anything she said after that. So we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.60</td>\n",
              "      <td>We wanted to start with a playing a video of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.01</td>\n",
              "      <td>1.16</td>\n",
              "      <td>And he is very, very modest, one of the most ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>25.01</td>\n",
              "      <td>25.16</td>\n",
              "      <td>out. How do we get into this part of technolo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>25.16</td>\n",
              "      <td>25.31</td>\n",
              "      <td>how we get everyone into this and this kind o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>25.31</td>\n",
              "      <td>25.46</td>\n",
              "      <td>But then there are basically vast numbers of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>25.46</td>\n",
              "      <td>26.01</td>\n",
              "      <td>Understand how to actually leverage this in a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>26.01</td>\n",
              "      <td>26.15</td>\n",
              "      <td>can ever see these tools. Thank you. Thank yo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6cef982-9ad0-4f67-9ffa-aedb2d125dca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6cef982-9ad0-4f67-9ffa-aedb2d125dca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6cef982-9ad0-4f67-9ffa-aedb2d125dca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c23ec4c-6e54-4b49-96bc-bf95073946ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c23ec4c-6e54-4b49-96bc-bf95073946ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c23ec4c-6e54-4b49-96bc-bf95073946ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_91dad182-be8f-4889-876d-8fb1857ec6a4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_91dad182-be8f-4889-876d-8fb1857ec6a4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     start_time  end_time                                               text\n",
              "0          0.00      0.15   Congratulations to you Mr. Raghavan for that....\n",
              "1          0.16      0.30   Energy downer or something? Let's hear it. Ar...\n",
              "2          0.31      0.45   Honestly, anything she said after that. So we...\n",
              "3          0.46      0.60   We wanted to start with a playing a video of ...\n",
              "4          1.01      1.16   And he is very, very modest, one of the most ...\n",
              "..          ...       ...                                                ...\n",
              "100       25.01     25.16   out. How do we get into this part of technolo...\n",
              "101       25.16     25.31   how we get everyone into this and this kind o...\n",
              "102       25.31     25.46   But then there are basically vast numbers of ...\n",
              "103       25.46     26.01   Understand how to actually leverage this in a...\n",
              "104       26.01     26.15   can ever see these tools. Thank you. Thank yo...\n",
              "\n",
              "[105 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "n = len(result)\n",
        "\n",
        "data_set = []\n",
        "\n",
        "element_no = 4\n",
        "\n",
        "for i in range(0, n):\n",
        "\n",
        "    start_time = ((i*0.15)+0.01)\n",
        "    end_time = start_time + 0.14\n",
        "\n",
        "    if i == 0:\n",
        "        start_time = 0\n",
        "        end_time = 00.15\n",
        "        data_set.append({'start_time': start_time, 'end_time': end_time, 'text': result[i]})\n",
        "\n",
        "    elif i < (n - 1):\n",
        "\n",
        "        if start_time <= 0.60 and end_time <= 0.60:\n",
        "            data_set.append({'start_time': start_time, 'end_time': end_time,\n",
        "                            'text': result[i]})\n",
        "        else:\n",
        "                j = i - 3\n",
        "\n",
        "                start_min = j\n",
        "                end_min = j\n",
        "\n",
        "                for k in range(0, 4):\n",
        "\n",
        "                        start_sec = (k*15) + 1\n",
        "\n",
        "                        end_sec = start_sec + 15\n",
        "\n",
        "                        if start_sec >= 60:\n",
        "                            start_min = j + 1\n",
        "                            start_sec = int(str(start_sec)[1])\n",
        "\n",
        "                        if end_sec >= 60:\n",
        "                            end_min = j + 1\n",
        "                            end_sec = int(str(end_sec)[1])\n",
        "\n",
        "                        if end_min > j:\n",
        "                            end_min = j + 1\n",
        "\n",
        "                        start_time = float(f'{start_min}.{start_sec:02d}')\n",
        "                        end_time = float(f'{end_min}.{end_sec:02d}')\n",
        "\n",
        "                        data_set.append({'start_time': start_time, 'end_time': end_time})\n",
        "\n",
        "                        if data_set[element_no - 1].get('text') != result[n - 2]:\n",
        "                            data_set[element_no].update({'text': result[i]})\n",
        "                element_no += 1\n",
        "\n",
        "\n",
        "    else:\n",
        "      data_set.append({'start_time': data_set[element_no - 1].get('end_time'), 'end_time': 26.15, 'text': result[i]})\n",
        "\n",
        "unwanted_data_set = []\n",
        "\n",
        "for t in range(len(data_set)):\n",
        "    if t > (element_no - 1) and t < (len(data_set) - 1):\n",
        "        unwanted_data_set.append(data_set[t])\n",
        "\n",
        "for d in unwanted_data_set:\n",
        "    if d in data_set:\n",
        "        data_set.remove(d)\n",
        "\n",
        "# convert dataset to a dataframe\n",
        "\n",
        "df = pd.DataFrame(data_set)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcZu_6nk5Frw"
      },
      "source": [
        "## Creating list of dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaDd-gZN52Rr",
        "outputId": "bf839608-c282-4f56-a484-e997c81d5dea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'chunk_id': 4,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" And he is very, very modest, one of the most modest guys that I know. But his personal journey, Vivek, you've been, you've got a PhD from Carnegie Mellon, you've sat it and sold the company to Magma. And Vivek and I moved back to India from, we were both in the valley.\",\n",
              "  'start_time': 1.01,\n",
              "  'end_time': 1.16},\n",
              " {'chunk_id': 5,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" on the same day actually. And you've been in India for the last 16 years. And what most people don't know is your junior Adhar. He spent 13 years selflessly at Adhar. Nobody would have heard of him.\",\n",
              "  'start_time': 1.16,\n",
              "  'end_time': 1.31},\n",
              " {'chunk_id': 6,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' But he was a pioneering technology visionary behind Adar which we all take for granted today. So please give it out. Honestly when people when I think of selfless service truly',\n",
              "  'start_time': 1.31,\n",
              "  'end_time': 1.46},\n",
              " {'chunk_id': 7,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" Flasso is always think of the big. And since then he also was at AI for Baharat, which we're going to touch on, where he met Pratiusius, other co-founder, Pratiusius had a PhD from ETH at Zurich. He was in the IBM research.\",\n",
              "  'start_time': 1.46,\n",
              "  'end_time': 2.01},\n",
              " {'chunk_id': 8,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" search, you was at Microsoft Research playing a key role, and a faculty at IIT Madras, and at AI Fabaret. So that's a little brief introduction about them. These guys are modest, modest engineers, so they don't toot their own horn. So forgive me.\",\n",
              "  'start_time': 2.01,\n",
              "  'end_time': 2.16},\n",
              " {'chunk_id': 9,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" but putting their on in this case. But let's jump right in about the money. Funding. 41 million bucks man, that's a lot of money. Every entrepreneur here is saying, what the hell did guys do? What did the investor-\",\n",
              "  'start_time': 2.16,\n",
              "  'end_time': 2.31},\n",
              " {'chunk_id': 10,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" to see to write such a big check. No, I think it's a trend of what's going on in India. I think that for the very first time, I think the investors have looked at, let's try and build something deep.\",\n",
              "  'start_time': 2.31,\n",
              "  'end_time': 2.46},\n",
              " {'chunk_id': 11,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" take out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's really exciting and I think that about you know as as as well as my\",\n",
              "  'start_time': 2.46,\n",
              "  'end_time': 3.01},\n",
              " {'chunk_id': 12,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" I've been kind of working in kind of, you know, both digital public infrastructure and kind of non-profit kind of things. But when this whole thing of generative AI came about, I see\",\n",
              "  'start_time': 3.01,\n",
              "  'end_time': 3.16},\n",
              " {'chunk_id': 13,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' You know, we said, okay, how can I actually make a difference in this space? And I said, maybe this is the opportunity to actually come out and really build something, you know, and the only way that we realize that you can do it is actually in...',\n",
              "  'start_time': 3.16,\n",
              "  'end_time': 3.31},\n",
              " {'chunk_id': 14,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" in the private sector. And I think that's the, and then we went out there and we said, we want to build something which is a continuation, right? I mean, and fundamentally the question is, the reason of what we want to do at server mayi is we want to basically make gender.\",\n",
              "  'start_time': 3.31,\n",
              "  'end_time': 3.46},\n",
              " {'chunk_id': 15,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" AI available and accessible to the people in the country. And that's the intent. And when we said that we want to do this, there was a resonance in the investment community. And I think it's a responsibility to really to show.\",\n",
              "  'start_time': 3.46,\n",
              "  'end_time': 4.01},\n",
              " {'chunk_id': 16,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" that something like this can be built out of India. So we see that as confidence and a responsibility. And I also hope it's a trend that there are many more people like us who are backed. Because if you look at it, maybe it's a lot of...\",\n",
              "  'start_time': 4.01,\n",
              "  'end_time': 4.16},\n",
              " {'chunk_id': 17,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" Number in a, you know, in the Indian context, but in the global context, I think there is just there should be many many more entrepreneurs Who are back to do things in India's? I'm gonna come back to the many more entrepreneurs. I'm obviously, I'm gonna ask you about\",\n",
              "  'start_time': 4.16,\n",
              "  'end_time': 4.31},\n",
              " {'chunk_id': 18,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" is Krutrim. So we're going to come back to that question. But again, $41 million. All of what you said, you know, $2 million, that's a good amount of money for a startup which is not yet built anything.\",\n",
              "  'start_time': 4.31,\n",
              "  'end_time': 4.46},\n",
              " {'chunk_id': 19,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" What are you going to do with all this money? I can call the problem. I can have a perfect solution for the problem. I think in the last week I've got lots of calls, lots of people telling me how I can do. But I know you first, okay, I'll be landed.\",\n",
              "  'start_time': 4.46,\n",
              "  'end_time': 5.01},\n",
              " {'chunk_id': 20,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" the content is same there, I'm in the front of the queue. No, but honestly, I think the key thing in this is to putting together an amazing team. And we actually have an amazing team, but we believe that it is talent that will drive this kind of...\",\n",
              "  'start_time': 5.01,\n",
              "  'end_time': 5.16},\n",
              " {'chunk_id': 21,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" And so it is to get key talent. And of course, the other thing is compute. This is extremely expensive compute wise to actually do these kinds of things. And I think that those are the two primary things that we'd use this.\",\n",
              "  'start_time': 5.16,\n",
              "  'end_time': 5.31},\n",
              " {'chunk_id': 22,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" Okay, I'm computing in my own head as an entrepreneur talent. Okay, you have like 2015 people. How much are you paying these guys? But okay, well, you won't touch on that. But let's talk about what you guys actually built. What is open Hathi?\",\n",
              "  'start_time': 5.31,\n",
              "  'end_time': 5.46},\n",
              " {'chunk_id': 23,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' How would you explain OpenHatithu? Many people here who might not have known about it. So I think OpenHatithu is so first of all, right? We come from, I personally come from the open source ecosystem and we, and also from the DPI ecosystem.',\n",
              "  'start_time': 5.46,\n",
              "  'end_time': 6.01},\n",
              " {'chunk_id': 24,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey, there are these open source, large language models that exist, right? I mean, everybody knows about the Lama.',\n",
              "  'start_time': 6.01,\n",
              "  'end_time': 6.16},\n",
              " {'chunk_id': 25,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' Emily from Meta, there are others like Mistral, there are a bunch of open source, you know, large language models. And then we said, is there any way that take an existing open source model and teach it language?',\n",
              "  'start_time': 6.16,\n",
              "  'end_time': 6.31},\n",
              " {'chunk_id': 26,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' which skills, right? I mean, you know, and that is really the, you know, what we decide, what we said that can we do something like that? And is this a, you know, relatively frugal way of actually, you know, making models, you know.',\n",
              "  'start_time': 6.31,\n",
              "  'end_time': 6.46},\n",
              " {'chunk_id': 27,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' work in diverse languages because the truth is still today. I mean if you look at the amount of data and knowledge it is still English dominates these things. And I think that how do you actually take and make it understand Indian language under',\n",
              "  'start_time': 6.46,\n",
              "  'end_time': 7.01},\n",
              " {'chunk_id': 28,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" stand Indian context and all of those things in actually a inefficient way. And therefore this was an attempt through that and it's a open hearty is currently based on the Lama 7 billion model but will be releasing many\",\n",
              "  'start_time': 7.01,\n",
              "  'end_time': 7.16},\n",
              " {'chunk_id': 29,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" more models in different languages, different sizes, and things like that as part of this series. And of course, we will be building further models on those and doing other things to actually, and we'll also have endpoints that people can use.\",\n",
              "  'start_time': 7.16,\n",
              "  'end_time': 7.31},\n",
              " {'chunk_id': 30,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" So the film is definitely something that people can use to things. And that's the essence of what this OpenHap is. So what does it mean to people in the audience here who are either doing their own startups or a business or?\",\n",
              "  'start_time': 7.31,\n",
              "  'end_time': 7.46},\n",
              " {'chunk_id': 31,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" How should they look at open AI? I think the way you look at it is that one of the important things that we are doing is we're not just building\",\n",
              "  'start_time': 7.46,\n",
              "  'end_time': 8.01},\n",
              " {'chunk_id': 32,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' models. We are also going to be building a platform, a platform for developers where you can actually use a combination of various different kinds of models, some which are from us, some which are open source, some which may not be open source, and actually',\n",
              "  'start_time': 8.01,\n",
              "  'end_time': 8.16},\n",
              " {'chunk_id': 33,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" to actually pull together and figure out how to deploy, you know, generative AI applications at scale and understand and evaluate their performance in an efficient manner. And that's something that we are planning to do at this platform.\",\n",
              "  'start_time': 8.16,\n",
              "  'end_time': 8.31},\n",
              " {'chunk_id': 34,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" Form is, you know, in the next couple of months, will be coming out there. It will be available to developers. But of course, those who want to start with the open source things and hack with that, of course, please go ahead and do that as well. That's phenomenal.\",\n",
              "  'start_time': 8.31,\n",
              "  'end_time': 8.46},\n",
              " {'chunk_id': 35,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' But how does it compare to OpenAI itself or Google? See, at least the things that we are doing now. I mean, one of the things that when we thought about a building server, we said we want to build a full-storey building.',\n",
              "  'start_time': 8.46,\n",
              "  'end_time': 9.01},\n",
              " {'chunk_id': 36,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' Stack, Generate V.I. company, and different people have an understanding of the stack is that we need to know how to train models from scratch. We need to know how to figure out how to deploy models to solve real world use cases. And we need to.',\n",
              "  'start_time': 9.01,\n",
              "  'end_time': 9.16},\n",
              " {'chunk_id': 37,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" play in the ecosystem to make sure that we can actually deploy population scale applications. Right? So we were thinking about all of these things. But still the models we were talking about are, you know, fairly small models. They're fairly small.\",\n",
              "  'start_time': 9.16,\n",
              "  'end_time': 9.31},\n",
              " {'chunk_id': 38,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" small models, right? The 7 to maybe up to 70 billion kind of range we're talking about. While these models like OpenAI and Google are obviously much bigger models, right? But we want to understand the techniques and be able to build that model.\",\n",
              "  'start_time': 9.31,\n",
              "  'end_time': 9.46},\n",
              " {'chunk_id': 39,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' So to do all of these things, to make it available to people. Now those models are, as I said, I think that there is space for all of those things. And I think, even Sridhar was talking about earlier.',\n",
              "  'start_time': 9.46,\n",
              "  'end_time': 10.01},\n",
              " {'chunk_id': 40,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' in the day. We believe that these smaller models can do many, many kind of domain specific tasks extremely well, probably even better than the larger models. And that is really one of the key areas.',\n",
              "  'start_time': 10.01,\n",
              "  'end_time': 10.16},\n",
              " {'chunk_id': 41,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" And so the value of these kinds of things, right? We are not aiming in these most set of models to build any AGI, right? That's not our goal here. Our goal is to make things that work extremely well for domain-specific use cases or increase\",\n",
              "  'start_time': 10.16,\n",
              "  'end_time': 10.31},\n",
              " {'chunk_id': 42,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' accessibility through language and all of those kinds of things. And obviously all of this unique to India. But what is unique about India? I mean, is anything special in our ecosystem that makes a small model focused with Indian languages?',\n",
              "  'start_time': 10.31,\n",
              "  'end_time': 10.46},\n",
              " {'chunk_id': 43,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': ' better for more suited for our problems. So I think that, I mean, there are quite a few things that are unique about India, right? The first thing is I think that we are a voice first nation. So therefore I think voice has to be the...',\n",
              "  'start_time': 10.46,\n",
              "  'end_time': 11.01},\n",
              " {'chunk_id': 44,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" The other thing, of course, India is extremely, it's a cost-conscious country from a cost perspective. Now, I would say that there are lots of interesting use cases where you can use open\",\n",
              "  'start_time': 11.01,\n",
              "  'end_time': 11.16},\n",
              " {'chunk_id': 45,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" AI and the cost structure works that when we're depending on your application, but when you want to scale things to a massive level and Make it work then then you have to figure out how small models work. So that's something that is also specific to India the third thing which is specific to\",\n",
              "  'start_time': 11.16,\n",
              "  'end_time': 11.31},\n",
              " {'chunk_id': 46,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' is really the success that India has had in building all this digital public infrastructure. When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative.',\n",
              "  'start_time': 11.31,\n",
              "  'end_time': 11.46},\n",
              " {'chunk_id': 47,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': ' based on doing things like that. building other, no better person than you.',\n",
              "  'start_time': 11.46,\n",
              "  'end_time': 12.01},\n",
              " {'chunk_id': 48,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" Specialized with trained with Indic specific language data suited for Indian problems at a compelling Cost point will be suited for us. We are not solving some world autonomous vehicles or some complex problem We're solving some basic problems\",\n",
              "  'start_time': 12.01,\n",
              "  'end_time': 12.16},\n",
              " {'chunk_id': 49,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' specifically focused on voice with multiple languages. That is what you see as a future. Am I paraphrasing this correctly? No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy. But we will be building custom models.',\n",
              "  'start_time': 12.16,\n",
              "  'end_time': 12.31},\n",
              " {'chunk_id': 50,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" to solve various other kinds of problems as well. Let's not just limited to, I think, in different domains, working in different domains, making building things based on unique data that enterprises have and things like that. So that's something that we'll also look at.\",\n",
              "  'start_time': 12.31,\n",
              "  'end_time': 12.46},\n",
              " {'chunk_id': 51,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': \" Fair enough. So coming back to the elephant in the room, no fun intended with open Hathi. What about Bavi, Shakirwal and Krutram? What is your take on that? I think it's great. I think it's wonderful, right? I mean the fact that\",\n",
              "  'start_time': 12.46,\n",
              "  'end_time': 13.01},\n",
              " {'chunk_id': 52,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' The technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is an important problem to be solved. And I think that we need...',\n",
              "  'start_time': 13.01,\n",
              "  'end_time': 13.16},\n",
              " {'chunk_id': 53,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" Everybody to come together and do that. So I really welcome that. I think it's great and I think that There'll be different people will have different takes as to how to solve this kind of problem and and hopefully as a result of that the entire ecosystem\",\n",
              "  'start_time': 13.16,\n",
              "  'end_time': 13.31},\n",
              " {'chunk_id': 54,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" benefits. One more question and then I want to talk about some of the predictions that you've boldly made. So Vivek, I usually ask people about what do you think the future will be and everybody usually hedges. I ask Vivek, what do you think is going to happen by December 2024?\",\n",
              "  'start_time': 13.31,\n",
              "  'end_time': 13.46},\n",
              " {'chunk_id': 55,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': ' Do you think sitting in this room one year later, we can expect? And you made three bold predictions. So I want to talk about that before that I have one last question. What are the top three applications that you think are relevant for India? You would see the talk about medical.',\n",
              "  'start_time': 13.46,\n",
              "  'end_time': 14.01},\n",
              " {'chunk_id': 56,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' What do you think your top three apps are for India for AI? I think that as you said things like education and medical are clearly areas where I think that things can be leveraged.',\n",
              "  'start_time': 14.01,\n",
              "  'end_time': 14.16},\n",
              " {'chunk_id': 57,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" The whole idea of all these kind of the DPI aspect of it is another major application where things can happen in and here I'm talking about country specific What and I think the whole idea which we've also talked about was the the concept of software right\",\n",
              "  'start_time': 14.16,\n",
              "  'end_time': 14.31},\n",
              " {'chunk_id': 58,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" And I think that, and clearly we have a very large software industry and and to how to reimagine those things in this context is also something that's going to be big. Fair enough. Are you guys ready for Vivek Aguayan's bold predictions? Yes?\",\n",
              "  'start_time': 14.31,\n",
              "  'end_time': 14.46},\n",
              " {'chunk_id': 59,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': \" No, I'm not hearing any yes. This is like a big deal. He's like one of the smartest guys that I know He wants to make three predictions. You don't want to hear it All right, so I asked him What do you think you know here later? What do you think we can expect? I need\",\n",
              "  'start_time': 14.46,\n",
              "  'end_time': 15.01},\n",
              " {'chunk_id': 60,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" came up with three things and usually people give very blind answers when you ask questions like this because they don't want to be caught wrong. Not Vivek, Vivek is bold. So he basically said three things and I'm going to list out the three things and then he's asking about it. So number one, he says,\",\n",
              "  'start_time': 15.01,\n",
              "  'end_time': 15.16},\n",
              " {'chunk_id': 61,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" I will prefer to talk to an automated customer service than a real person because they'll give me a better answer. So that is Vivek Raghavan's prediction number one. So number two is that when everybody is talking about a GPU shortage.\",\n",
              "  'start_time': 15.16,\n",
              "  'end_time': 15.31},\n",
              " {'chunk_id': 62,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' The weight predicts that there will be a GPU glutton India. He thinks there will be too much GPU. So if you want a short and media start, this is a good time. And number three, which was extremely unexpected, he said some companies will suddenly die.',\n",
              "  'start_time': 15.31,\n",
              "  'end_time': 15.46},\n",
              " {'chunk_id': 63,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': \" Okay, so Vivek, these are not what I expected. So you want to quickly talk about each of them, why you just came up with these and then we'll throw the open for audience questions. So I don't think I quite said it the way that\",\n",
              "  'start_time': 15.46,\n",
              "  'end_time': 16.01},\n",
              " {'chunk_id': 64,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" But it's interesting. But I think the first thing that we said is, I think that, and I don't think that this is, I think there will come a time when, you know, in...\",\n",
              "  'start_time': 16.01,\n",
              "  'end_time': 16.16},\n",
              " {'chunk_id': 65,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" in areas of customer service, et cetera. When you want to do something very specific, today, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call, or you're extremely upset that you're...\",\n",
              "  'start_time': 16.16,\n",
              "  'end_time': 16.31},\n",
              " {'chunk_id': 66,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" talking to a bot. But I think that there will come a time, and I'm predicting it sooner than later, that you will actually get better responses from the bot than what the human representative, that at least the average human representative that you could talk to.\",\n",
              "  'start_time': 16.31,\n",
              "  'end_time': 16.46},\n",
              " {'chunk_id': 67,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': \" could give. And I think that that's just a, I just said that that there will come a time where you know it's not a human you're talking to, but it's probably more likely to solve your intent than the human person. That's just something that that\",\n",
              "  'start_time': 16.46,\n",
              "  'end_time': 17.01},\n",
              " {'chunk_id': 68,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" that I think that could happen. Definitely controversial, but we'll let it go. What about the GPU glut? No, I don't think that. So I think that the fact that there is a tremendous shortage right now.\",\n",
              "  'start_time': 17.01,\n",
              "  'end_time': 17.16},\n",
              " {'chunk_id': 69,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' I think that shortage will ease because that is how the cycles of things go, right? When you, when you, you know, I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in...',\n",
              "  'start_time': 17.16,\n",
              "  'end_time': 17.31},\n",
              " {'chunk_id': 70,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' areas, kinds of forms. And I think that that will always go in a cycle. But you may find out that there are many, many more interesting problems that people will be able to solve. I still remember, you know.',\n",
              "  'start_time': 17.31,\n",
              "  'end_time': 17.46},\n",
              " {'chunk_id': 71,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': ' We were at a Genie I event in Bangalore, and we were talking to people. And we said, how many people have access to 4 a 100? So this was the question that I asked. And nobody in the room. And these are all extremely enthusiastic Genie I.',\n",
              "  'start_time': 17.46,\n",
              "  'end_time': 18.01},\n",
              " {'chunk_id': 72,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' and nobody had access. And I think that thing is going to change. You will be able to get these kinds of things and people who want to hack and do things will have access to these things without having to write a major check.',\n",
              "  'start_time': 18.01,\n",
              "  'end_time': 18.16},\n",
              " {'chunk_id': 73,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" Vivek is also a semi-conductor guy before he went into Aadhar. So I would take his predictions very seriously. So I don't know what I'm going to sell my immediate stock. I would not do that. But that's not what I said. I want to blame you for this. It goes up.\",\n",
              "  'start_time': 18.16,\n",
              "  'end_time': 18.31},\n",
              " {'chunk_id': 74,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' But the third one is pretty strange. Companies are born, companies die, but you said some companies will suddenly die. What does that mean? No, I think the interesting thing is, and I think that it comes back to',\n",
              "  'start_time': 18.31,\n",
              "  'end_time': 18.46},\n",
              " {'chunk_id': 75,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': \" to the fundamental nature of AI. AI is a tool, right? And you have to use that. And you have to use that within your business process, right? And how AI is being used, and so what's going to happen is that, I mean, I think this is true.\",\n",
              "  'start_time': 18.46,\n",
              "  'end_time': 19.01},\n",
              " {'chunk_id': 76,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" with, you know, when someone said in terms of, you know, people, they said that the people who leverage AI will be more effective than those who don't leverage AI. And that will stood for organizations also.\",\n",
              "  'start_time': 19.01,\n",
              "  'end_time': 19.16},\n",
              " {'chunk_id': 77,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" stations that leverage AI in fundamentally in their core business processes will be more effective than those who don't. And I think that's the thing. You won't know the difference until one day it becomes too obvious and it will be too\",\n",
              "  'start_time': 19.16,\n",
              "  'end_time': 19.31},\n",
              " {'chunk_id': 78,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" And I think that's the reason why everybody needs to think about what it means for your business. Because everything will be fine. Everything will be fine. And one day somebody in your, either your competitors,\",\n",
              "  'start_time': 19.31,\n",
              "  'end_time': 19.46},\n",
              " {'chunk_id': 79,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': \" your space or somebody brand new coming into your space will be reimagining your business process completely and at that stage you will find that it's a very big, very tall mountain to climb and that's why I think it's important.\",\n",
              "  'start_time': 19.46,\n",
              "  'end_time': 20.01},\n",
              " {'chunk_id': 80,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" important for both people and entities to think about how they will you know they will upgrade themselves or they will modify their business processes to a tour. That's a very nuanced answer and everybody here who's running a business should really think about\",\n",
              "  'start_time': 20.01,\n",
              "  'end_time': 20.16},\n",
              " {'chunk_id': 81,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" it because life will be the same and then suddenly something will be a step change. We make a few more questions but I'm sure the audience has a lot of questions for you. So how are we doing on time? Okay.\",\n",
              "  'start_time': 20.16,\n",
              "  'end_time': 20.31},\n",
              " {'chunk_id': 82,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' Does okay a lot of questions so love to is there a mic that we can Thank you my name is Kartik I work for',\n",
              "  'start_time': 20.31,\n",
              "  'end_time': 20.46},\n",
              " {'chunk_id': 83,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': ' the service industry. So you are saying that you are working on LLM sorry it is fine tuned LLM on top of LAMA. My basic question fundamental question is we do not have a foundation model for India. Most of the',\n",
              "  'start_time': 20.46,\n",
              "  'end_time': 21.01},\n",
              " {'chunk_id': 84,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' models are basically using English or those kind of things. So for example, Andrew was talking about the tokenizers and things like that. So are you working on anything like that? Or do you want to use mostly...',\n",
              "  'start_time': 21.01,\n",
              "  'end_time': 21.16},\n",
              " {'chunk_id': 85,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" the existing models and run on top of it. Are you going to ask a good question? You ask a cherry question for himself. No, I think the interesting thing is that if you look at, and then we have actually a blog on this on our website, I think one of the things that we've been, we actually,\",\n",
              "  'start_time': 21.16,\n",
              "  'end_time': 21.31},\n",
              " {'chunk_id': 86,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' a customized tokenizer which actually fundamentally changes the cost of some of these generations in Indian languages. And I think that we are not just fine tuning, we are actually, we are leveraging the existing pre-taining mode.',\n",
              "  'start_time': 21.31,\n",
              "  'end_time': 21.46},\n",
              " {'chunk_id': 87,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': \" We are doing what's known as continual free training, which actually, but having said that, you know, I think that when we have to figure out where is the data to train an extremely large model from scratch and some of those things are things which will happen.\",\n",
              "  'start_time': 21.46,\n",
              "  'end_time': 22.01},\n",
              " {'chunk_id': 88,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': \" time. But I think that yes, I think that we will be doing various kinds of things. But the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that? And that's the\",\n",
              "  'start_time': 22.01,\n",
              "  'end_time': 22.16},\n",
              " {'chunk_id': 89,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" problem that we have that we think we have solved and is going to be the heart of this open up. It's extremely well explained in the blog even I could understand it. Hi, I'm Prishant. I work for a fit deck company. My question is like.\",\n",
              "  'start_time': 22.16,\n",
              "  'end_time': 22.31},\n",
              " {'chunk_id': 90,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' Unlike China, we never had a consumer facing application coming out from India and in Web One, Web Two, crypto and all. Why do you think it will be different this time in like AI?',\n",
              "  'start_time': 22.31,\n",
              "  'end_time': 22.46},\n",
              " {'chunk_id': 91,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': ' Will the BPI and other things will sub the same purpose, but the great five world did in China? Or do you think like in, because AI is a strategic sector, no outside country can work.',\n",
              "  'start_time': 22.46,\n",
              "  'end_time': 23.01},\n",
              " {'chunk_id': 92,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' in NASA projects maybe for government content will go to them what at least the mode here for an Indian company? I think the question...',\n",
              "  'start_time': 23.01,\n",
              "  'end_time': 23.16},\n",
              " {'chunk_id': 93,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" is I don't know the answer to these questions, right? I mean, I think that it's difficult to predict. But I do believe, and as I'm repeating, that the combinatorial effect of being using Gen AI at a large scale.\",\n",
              "  'start_time': 23.16,\n",
              "  'end_time': 23.31},\n",
              " {'chunk_id': 94,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" in addition, along with the DPI work that we've done in India, will have people. And I think that in the end, the intent is that people need to be able to use it. And they will vote by things that are useful for them. And if that doesn't happen,\",\n",
              "  'start_time': 23.31,\n",
              "  'end_time': 23.46},\n",
              " {'chunk_id': 95,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': \" happen, you're right, that I think that we have to figure out what is the mechanism of delivery of apps, right? I mean, in how, where do Indians consume content? That's a question. I'm so sorry, but we are out of time.\",\n",
              "  'start_time': 23.46,\n",
              "  'end_time': 24.01},\n",
              " {'chunk_id': 96,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' outside. So he would be able to answer the question. We have time for one last question. Can I just take one last? Thank you. Thank you. I am Manish Kudhari. I am from ISBR Business School. Good that I got a chance to ask you this question. During lunch time, there were a few of us.',\n",
              "  'start_time': 24.01,\n",
              "  'end_time': 24.16},\n",
              " {'chunk_id': 97,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': ' educationists whom we were talking about and there was one from school and we are from the MBA institutions. We were thinking of these present generations, how do we get them into what you are doing? There is one thing that they have been regularly that the...',\n",
              "  'start_time': 24.16,\n",
              "  'end_time': 24.31},\n",
              " {'chunk_id': 98,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" concentrations that they're working on, but artificial intelligence and getting into this, getting them into their academics and making them a part of it is very important, including the trainers who train them, making them future ready into what you are doing is amazing. And the speed that\",\n",
              "  'start_time': 24.31,\n",
              "  'end_time': 24.46},\n",
              " {'chunk_id': 99,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': ' which is growing, it is calling for a lot of training that needs to be done. Can you from your angle through some light on how we could make them future ready? How these people who are management graduates and from schools who are coming to the world?',\n",
              "  'start_time': 24.46,\n",
              "  'end_time': 25.01},\n",
              " {'chunk_id': 100,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' out. How do we get into this part of technology that you spoke about? Oh, so this is really a challenge because I think everyone will need to understand at some level what this technology does. And I think that we have to rethink.',\n",
              "  'start_time': 25.01,\n",
              "  'end_time': 25.16},\n",
              " {'chunk_id': 101,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" how we get everyone into this and this kind of education has to be at many different levels. There are from a core set of having people who are extremely good at some and there you don't need as many.\",\n",
              "  'start_time': 25.16,\n",
              "  'end_time': 25.31},\n",
              " {'chunk_id': 102,\n",
              "  'chunk_length': -0.15,\n",
              "  'text': \" But then there are basically vast numbers of people who can actually leverage these tools. By the way, the most important thing about, and maybe that's part of what makes an LLM interesting, is that how you use it, your mileage varies by that. And to us...\",\n",
              "  'start_time': 25.31,\n",
              "  'end_time': 25.46},\n",
              " {'chunk_id': 103,\n",
              "  'chunk_length': 0.45,\n",
              "  'text': ' Understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people. And because asking the things in the right way and having the right kind of applications will make a huge difference.',\n",
              "  'start_time': 25.46,\n",
              "  'end_time': 26.01},\n",
              " {'chunk_id': 104,\n",
              "  'chunk_length': 0.15,\n",
              "  'text': ' can ever see these tools. Thank you. Thank you very much. Thank you Mr. Raghavan and',\n",
              "  'start_time': 26.01,\n",
              "  'end_time': 26.15}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    chunk_id = index\n",
        "\n",
        "    if row['start_time'] >= 1 and row['end_time'] >= 1:\n",
        "\n",
        "        if row['start_time'] < 10 and row['end_time'] < 10:\n",
        "            chunk_start_min = int(str(row['start_time'])[0:1])\n",
        "            chunk_start_sec = int(str(row['start_time'])[2:4])\n",
        "\n",
        "            chunk_end_min = int(str(row['end_time'])[0:1])\n",
        "            chunk_end_sec = int(str(row['end_time'])[2:4])\n",
        "\n",
        "        elif row['start_time'] < 10 and row['end_time'] >= 10:\n",
        "            chunk_start_min = int(str(row['start_time'])[0:1])\n",
        "            chunk_end_min = int(str(row['start_time'])[2:4])\n",
        "\n",
        "            chunk_end_min = int(str(row['end_time'])[0:2])\n",
        "            chunk_end_sec = int(str(row['end_time'])[3:5])\n",
        "\n",
        "        elif row['start_time'] > 10:\n",
        "            chunk_start_min = int(str(row['start_time'])[0:2])\n",
        "            chunk_start_sec = int(str(row['end_time'])[3:5])\n",
        "\n",
        "            chunk_end_min = int(str(row['start_time'])[0:2])\n",
        "            chunk_end_sec = int(str(row['start_time'])[3:5])\n",
        "\n",
        "        if chunk_start_sec == 1:\n",
        "            chunk_start_sec = format(1, \"02d\")\n",
        "\n",
        "        if chunk_end_sec == 1:\n",
        "            chunk_end_sec = format(1, \"02d\")\n",
        "            chunk_length = 0.15\n",
        "\n",
        "        else:\n",
        "            chunk_start_time = float(f'{chunk_start_min}.{chunk_start_sec}')\n",
        "            chunk_end_time = float(f'{chunk_end_min}.{chunk_end_sec}')\n",
        "\n",
        "            chunk_length = round(chunk_end_time - chunk_start_time, 2)\n",
        "\n",
        "        chunks.append(\n",
        "      {\n",
        "        'chunk_id': chunk_id,\n",
        "        'chunk_length': chunk_length,\n",
        "        'text': row['text'],\n",
        "        'start_time': row['start_time'],\n",
        "        'end_time': row['end_time']\n",
        "      }\n",
        "    )\n",
        "\n",
        "chunks"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPbLuFGhpRZpeJ5MWk2505I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}